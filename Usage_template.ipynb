{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, gffutils, re, HTSeq\n",
    "import geneDrawingUtils, plot_interval\n",
    "importlib.reload(plot_interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Building a gffutils database object.\n",
    "\n",
    "Original document header:\n",
    "    https://www.biostars.org/p/152517/\n",
    "    Example of how to work with Ensembl release 81 GTF files, which:\n",
    "        1) already have genes and transcripts included\n",
    "        2) have unique IDs for genes, transcripts, and exons in the corresponding\n",
    "           \"<featuretype>_id\" attribute\n",
    "        3) do not have unique IDs for CDS, stop_codon, start_codon, UTR.\n",
    "    See background info at on database IDs at:\n",
    "        https://pythonhosted.org/gffutils/database-ids.html\n",
    "    GTF file from\n",
    "    ftp://ftp.ensembl.org/pub/release-81/gtf/mus_musculus/Mus_musculus.GRCm38.81.gtf.gz\n",
    "\n",
    "For humans, the GTF file was obtained from:\n",
    "http://ftp.ensembl.org/pub/release-104/gtf/homo_sapiens/Homo_sapiens.GRCh38.104.chr.gtf.gz   \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import gffutils, sys\n",
    "\n",
    "def first_n_features(data, n=5000):\n",
    "    \"\"\"\n",
    "    Useful for testing: only use the first `n` features of source data\n",
    "    \"\"\"\n",
    "    for i, feature in enumerate(gffutils.iterators.DataIterator(data)):\n",
    "        if i > n:\n",
    "            break\n",
    "        yield feature\n",
    "\n",
    "\n",
    "# Note: this function is optional; if you don't want these IDs then comment out \n",
    "# the lines at [1] below\n",
    "def subfeature_handler(f):\n",
    "    \"\"\"\n",
    "    Given a gffutils.Feature object (which does not yet have its ID assigned),\n",
    "    figure out what its ID should be.\n",
    "    This is intended to be used for CDS, UTR, start_codon, and stop_codon\n",
    "    features in the Ensembl release 81 GTF files.  I figured a reasonable\n",
    "    unique ID would consist of the parent transcript and the feature type,\n",
    "    followed by an autoincrementing number.\n",
    "    See https://pythonhosted.org/gffutils/database-ids.html#id-spec for\n",
    "    details and other options.\n",
    "    \"\"\"\n",
    "    return ''.join(\n",
    "        ['autoincrement:',\n",
    "         f.attributes['transcript_id'][0],\n",
    "         '_',\n",
    "         f.featuretype])\n",
    "\n",
    "\n",
    "# gffutils can spend a lot of time trying to decide on a unique ID for each\n",
    "# feature. So we have to give it hints of where to look in the attributes.\n",
    "#\n",
    "# We also tell it to use our subfeature_handler function for featuretypes with\n",
    "# no unique IDs.\n",
    "id_spec = {\n",
    "    'exon': 'exon_id',\n",
    "    'gene': 'gene_id',\n",
    "    'transcript': 'transcript_id',\n",
    "\n",
    "    # [1] These aren't needed for speed, but they do give nicer IDs.\n",
    "    'CDS': [subfeature_handler],\n",
    "    'stop_codon': [subfeature_handler],\n",
    "    'start_codon': [subfeature_handler],\n",
    "    'UTR':  [subfeature_handler],\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Download a gtf of genome annotations.\n",
    "\n",
    "# Download the annotation GTF and unzip:\n",
    "# wget http://ftp.ensembl.org/pub/release-104/gtf/homo_sapiens/Homo_sapiens.GRCh38.104.chr.gtf.gz\n",
    "# gunzip Homo_sapiens.GRCh38.104.chr.gtf.gz\n",
    "\n",
    "# 2. Build the features.db object from the gtf.\n",
    "gtf_filename = \"Homo_sapiens.GRCh38.104.chr.gtf\"\n",
    "db = gffutils.create_db(\n",
    "    gtf_filename,\n",
    "    'assets/reference/features.no_introns.db',\n",
    "\n",
    "    # Since Ensembl GTF files now come with genes and transcripts already in\n",
    "    # the file, we don't want to spend the time to infer them (which we would\n",
    "    # need to do in an on-spec GTF file)\n",
    "    disable_infer_genes=True,\n",
    "    disable_infer_transcripts=True,\n",
    "\n",
    "    # Here's where we provide our custom id spec\n",
    "    id_spec=id_spec,\n",
    "\n",
    "    # \"create_unique\" runs a lot faster than \"merge\"\n",
    "    # See https://pythonhosted.org/gffutils/database-ids.html#merge-strategy\n",
    "    # for details.\n",
    "    merge_strategy='create_unique',\n",
    "    verbose=True,\n",
    "    force=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create introns.\n",
    "# This takes a long time.\n",
    "\n",
    "intronDb = db.create_introns(exon_featuretype='exon', grandparent_featuretype='transcript')\n",
    "\n",
    "# Using the recommended strategy of db.update() fails in my hands, so instead we use a work-around.\n",
    "# We write a new gtf on just the introns.\n",
    "with open('introns.gtf', 'w') as f:\n",
    "    for li in intronDb:\n",
    "        f.write(str(li) + '\\n')\n",
    "\n",
    "# Then concatenate the original gtf and the introns:\n",
    "# cat Homo_sapiens.GRCh38.104.chr.gtf introns.gtf > Homo_sapiens.GRCh38.104.chr.with_introns.gtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new db, this time with introns.\n",
    "gtf_filename = \"Homo_sapiens.GRCh38.104.chr.with_introns.gtf\"\n",
    "db = gffutils.create_db(\n",
    "    gtf_filename,\n",
    "    'features.db',\n",
    "\n",
    "    # Since Ensembl GTF files now come with genes and transcripts already in\n",
    "    # the file, we don't want to spend the time to infer them (which we would\n",
    "    # need to do in an on-spec GTF file)\n",
    "    disable_infer_genes=True,\n",
    "    disable_infer_transcripts=True,\n",
    "\n",
    "    # Here's where we provide our custom id spec\n",
    "    id_spec=id_spec,\n",
    "\n",
    "    # \"create_unique\" runs a lot faster than \"merge\"\n",
    "    # See https://pythonhosted.org/gffutils/database-ids.html#merge-strategy\n",
    "    # for details.\n",
    "    merge_strategy='create_unique',\n",
    "    verbose=True,\n",
    "    force=True,\n",
    ")\n",
    "\n",
    "# The genome annotation object is now complete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Load the input data.\n",
    "import importlib, gffutils, re, HTSeq\n",
    "import geneDrawingUtils, plot_interval\n",
    "importlib.reload(plot_interval)\n",
    "\n",
    "db = gffutils.FeatureDB('features.db', keep_order=True)\n",
    "list(db.featuretypes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a fasta if desired to write motif coverage.\n",
    "genomic_fasta_fname = '/opt/genomes/gencode.v29/GRCh38.primary_assembly.genome.fa.gz'  # Newer, separate mapping.\n",
    "genomic_fasta = dict( (s[1], s[0]) for s in HTSeq.FastaReader(genomic_fasta_fname, raw_iterator=True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Plotting.\n",
    "importlib.reload(plot_interval)\n",
    "bw_fnames = {\n",
    "    'Group1': ['data/Example_group1_rep1.bigwig', 'data/Example_group1_rep2.bigwig'],\n",
    "    'Group2': ['data/Example_group2_rep1.bigwig', 'data/Example_group2_rep2.bigwig'],}\n",
    "\n",
    "\n",
    "def igv_to_list(_str):\n",
    "    chrom, rest = _str.split(':')\n",
    "    rest = re.sub(',', '', rest)\n",
    "    start, end = rest.split('-')\n",
    "    return [chrom, int(start), int(end), '+']\n",
    "\n",
    "\n",
    "motif = \"[AT]GTGT[AT]\"  # WGTGTW.\n",
    "#iv = \"chr4:151,097,347-151,106,361\"  # RPS3aA\n",
    "iv = \"chr11:65,785,063-65,799,214\"  # OVOL1\n",
    "#iv = \"chr14:24,247,114-24,265,177\"  # TGM1\n",
    "#iv = 'chr1:24,317,357-24,366,482'  # GRHL3\n",
    "#iv = \"chr17:41,752,607-41,788,768\"  # JUP\n",
    "\n",
    "clip_sites = [\n",
    "    \"chr17:41,752,607-41,788,768\",  # JUP\n",
    "    'chr1:24,317,357-24,366,482',  # GRHL3\n",
    "    \"chr14:24,247,114-24,265,177\",  # TGM1\n",
    "    \"chr11:65,785,063-65,799,214\",  # OVOL1\n",
    "]\n",
    "#iv = igv_to_list(iv)\n",
    "_iv = [igv_to_list(x) for x in clip_sites]\n",
    "for iv in _iv:\n",
    "    plot_interval.plot_interval(iv, bw_fnames=bw_fnames, genomic_fasta=genomic_fasta, window=100, db=db, motif=motif, plot_replicates=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
